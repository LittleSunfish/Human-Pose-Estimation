{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, reduced_channels, out_channels, stride=1, starting=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, reduced_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(reduced_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ) \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(reduced_channels, reduced_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(reduced_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(reduced_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != 4*reduced_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, 4*reduced_channels,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(4*reduced_channels)\n",
    "            )\n",
    "\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out) + self.shortcut(x)\n",
    "        out = self.final_relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.num_blocks = [3,4,6,3]\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=4),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv2 = self._make_layer(in_channels=64, reduced_channels=64, out_channels=256, num_blocks=self.num_blocks[0], stride=1)\n",
    "        self.conv3 = self._make_layer(in_channels=256, reduced_channels=128, out_channels=512, num_blocks=self.num_blocks[1], stride=1)\n",
    "        self.conv4 = self._make_layer(in_channels=512, reduced_channels=256, out_channels=1024, num_blocks=self.num_blocks[2], stride=1)\n",
    "        self.conv5 = self._make_layer(in_channels=1024, reduced_channels=512, out_channels=2048, num_blocks=self.num_blocks[3], stride=1)\n",
    "        \n",
    "        self.avg = nn.AvgPool2d(kernel_size=4)\n",
    "        # FC layer, after applied 'avg pooling'\n",
    "        # self.fc1 = nn.Sequential(\n",
    "        #     nn.Linear(in_features=2048, out_features=1000)\n",
    "        # )\n",
    "\n",
    "        # reduce the number of channel to 17 -> number of keypoints\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2048, out_channels=17, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_channels, reduced_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "\n",
    "        for i, s in enumerate(strides):\n",
    "            bottleneck_layer = Bottleneck(in_channels, reduced_channels, out_channels, s)\n",
    "            layers.append(bottleneck_layer)\n",
    "            in_channels = reduced_channels *4\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)   \n",
    "        out = self.conv2(out)   # output: 256*64*48\n",
    "        out = self.conv3(out)   # output: 512*32*24\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)   # output: 16*12\n",
    "        #out = self.avg(out)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "\n",
    "        ## the input of last layer shoul be in size 64x48 before\n",
    "        out = self.final(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 129, 97]           9,472\n",
      "       BatchNorm2d-2          [-1, 64, 129, 97]             128\n",
      "              ReLU-3          [-1, 64, 129, 97]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 48]               0\n",
      "            Conv2d-5           [-1, 64, 64, 48]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 48]             128\n",
      "              ReLU-7           [-1, 64, 64, 48]               0\n",
      "            Conv2d-8           [-1, 64, 64, 48]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 48]             128\n",
      "             ReLU-10           [-1, 64, 64, 48]               0\n",
      "           Conv2d-11          [-1, 256, 64, 48]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 48]             512\n",
      "           Conv2d-13          [-1, 256, 64, 48]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 48]             512\n",
      "             ReLU-15          [-1, 256, 64, 48]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 48]               0\n",
      "           Conv2d-17           [-1, 64, 64, 48]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 64, 48]             128\n",
      "             ReLU-19           [-1, 64, 64, 48]               0\n",
      "           Conv2d-20           [-1, 64, 64, 48]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 64, 48]             128\n",
      "             ReLU-22           [-1, 64, 64, 48]               0\n",
      "           Conv2d-23          [-1, 256, 64, 48]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 64, 48]             512\n",
      "             ReLU-25          [-1, 256, 64, 48]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 48]               0\n",
      "           Conv2d-27           [-1, 64, 64, 48]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 64, 48]             128\n",
      "             ReLU-29           [-1, 64, 64, 48]               0\n",
      "           Conv2d-30           [-1, 64, 64, 48]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 48]             128\n",
      "             ReLU-32           [-1, 64, 64, 48]               0\n",
      "           Conv2d-33          [-1, 256, 64, 48]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 64, 48]             512\n",
      "             ReLU-35          [-1, 256, 64, 48]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 48]               0\n",
      "           Conv2d-37          [-1, 128, 64, 48]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 64, 48]             256\n",
      "             ReLU-39          [-1, 128, 64, 48]               0\n",
      "           Conv2d-40          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 64, 48]             256\n",
      "             ReLU-42          [-1, 128, 64, 48]               0\n",
      "           Conv2d-43          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 64, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 64, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 64, 48]               0\n",
      "           Conv2d-49          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 64, 48]             256\n",
      "             ReLU-51          [-1, 128, 64, 48]               0\n",
      "           Conv2d-52          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 64, 48]             256\n",
      "             ReLU-54          [-1, 128, 64, 48]               0\n",
      "           Conv2d-55          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 64, 48]               0\n",
      "           Conv2d-59          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 64, 48]             256\n",
      "             ReLU-61          [-1, 128, 64, 48]               0\n",
      "           Conv2d-62          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 64, 48]             256\n",
      "             ReLU-64          [-1, 128, 64, 48]               0\n",
      "           Conv2d-65          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 64, 48]               0\n",
      "           Conv2d-69          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 64, 48]             256\n",
      "             ReLU-71          [-1, 128, 64, 48]               0\n",
      "           Conv2d-72          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 64, 48]             256\n",
      "             ReLU-74          [-1, 128, 64, 48]               0\n",
      "           Conv2d-75          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 64, 48]               0\n",
      "           Conv2d-79          [-1, 256, 64, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 64, 48]             512\n",
      "             ReLU-81          [-1, 256, 64, 48]               0\n",
      "           Conv2d-82          [-1, 256, 64, 48]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 64, 48]             512\n",
      "             ReLU-84          [-1, 256, 64, 48]               0\n",
      "           Conv2d-85         [-1, 1024, 64, 48]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 64, 48]           2,048\n",
      "           Conv2d-87         [-1, 1024, 64, 48]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 64, 48]           2,048\n",
      "             ReLU-89         [-1, 1024, 64, 48]               0\n",
      "       Bottleneck-90         [-1, 1024, 64, 48]               0\n",
      "           Conv2d-91          [-1, 256, 64, 48]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 64, 48]             512\n",
      "             ReLU-93          [-1, 256, 64, 48]               0\n",
      "           Conv2d-94          [-1, 256, 64, 48]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 64, 48]             512\n",
      "             ReLU-96          [-1, 256, 64, 48]               0\n",
      "           Conv2d-97         [-1, 1024, 64, 48]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 64, 48]           2,048\n",
      "             ReLU-99         [-1, 1024, 64, 48]               0\n",
      "      Bottleneck-100         [-1, 1024, 64, 48]               0\n",
      "          Conv2d-101          [-1, 256, 64, 48]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 64, 48]             512\n",
      "            ReLU-103          [-1, 256, 64, 48]               0\n",
      "          Conv2d-104          [-1, 256, 64, 48]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 64, 48]             512\n",
      "            ReLU-106          [-1, 256, 64, 48]               0\n",
      "          Conv2d-107         [-1, 1024, 64, 48]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 64, 48]           2,048\n",
      "            ReLU-109         [-1, 1024, 64, 48]               0\n",
      "      Bottleneck-110         [-1, 1024, 64, 48]               0\n",
      "          Conv2d-111          [-1, 256, 64, 48]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 64, 48]             512\n",
      "            ReLU-113          [-1, 256, 64, 48]               0\n",
      "          Conv2d-114          [-1, 256, 64, 48]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 64, 48]             512\n",
      "            ReLU-116          [-1, 256, 64, 48]               0\n",
      "          Conv2d-117         [-1, 1024, 64, 48]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 64, 48]           2,048\n",
      "            ReLU-119         [-1, 1024, 64, 48]               0\n",
      "      Bottleneck-120         [-1, 1024, 64, 48]               0\n",
      "          Conv2d-121          [-1, 256, 64, 48]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 64, 48]             512\n",
      "            ReLU-123          [-1, 256, 64, 48]               0\n",
      "          Conv2d-124          [-1, 256, 64, 48]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 64, 48]             512\n",
      "            ReLU-126          [-1, 256, 64, 48]               0\n",
      "          Conv2d-127         [-1, 1024, 64, 48]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 64, 48]           2,048\n",
      "            ReLU-129         [-1, 1024, 64, 48]               0\n",
      "      Bottleneck-130         [-1, 1024, 64, 48]               0\n",
      "          Conv2d-131          [-1, 256, 64, 48]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 64, 48]             512\n",
      "            ReLU-133          [-1, 256, 64, 48]               0\n",
      "          Conv2d-134          [-1, 256, 64, 48]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 64, 48]             512\n",
      "            ReLU-136          [-1, 256, 64, 48]               0\n",
      "          Conv2d-137         [-1, 1024, 64, 48]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 64, 48]           2,048\n",
      "            ReLU-139         [-1, 1024, 64, 48]               0\n",
      "      Bottleneck-140         [-1, 1024, 64, 48]               0\n",
      "          Conv2d-141          [-1, 512, 64, 48]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-143          [-1, 512, 64, 48]               0\n",
      "          Conv2d-144          [-1, 512, 64, 48]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-146          [-1, 512, 64, 48]               0\n",
      "          Conv2d-147         [-1, 2048, 64, 48]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 64, 48]           4,096\n",
      "          Conv2d-149         [-1, 2048, 64, 48]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 64, 48]           4,096\n",
      "            ReLU-151         [-1, 2048, 64, 48]               0\n",
      "      Bottleneck-152         [-1, 2048, 64, 48]               0\n",
      "          Conv2d-153          [-1, 512, 64, 48]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-155          [-1, 512, 64, 48]               0\n",
      "          Conv2d-156          [-1, 512, 64, 48]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-158          [-1, 512, 64, 48]               0\n",
      "          Conv2d-159         [-1, 2048, 64, 48]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 64, 48]           4,096\n",
      "            ReLU-161         [-1, 2048, 64, 48]               0\n",
      "      Bottleneck-162         [-1, 2048, 64, 48]               0\n",
      "          Conv2d-163          [-1, 512, 64, 48]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-165          [-1, 512, 64, 48]               0\n",
      "          Conv2d-166          [-1, 512, 64, 48]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 64, 48]           1,024\n",
      "            ReLU-168          [-1, 512, 64, 48]               0\n",
      "          Conv2d-169         [-1, 2048, 64, 48]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 64, 48]           4,096\n",
      "            ReLU-171         [-1, 2048, 64, 48]               0\n",
      "      Bottleneck-172         [-1, 2048, 64, 48]               0\n",
      "          Conv2d-173           [-1, 17, 64, 48]          34,833\n",
      "================================================================\n",
      "Total params: 23,542,929\n",
      "Trainable params: 23,542,929\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.56\n",
      "Forward/backward pass size (MB): 2147.23\n",
      "Params size (MB): 89.81\n",
      "Estimated Total Size (MB): 2237.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "resnet = ResNet50().cuda()\n",
    "summary(resnet, input_size=(3,256,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reset_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epoch, loader, optimizer, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(input=outputs, target=labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('Epoch {}, loss = {:.3f}'.format(epoch, running_loss/len(loader)))\n",
    "    \n",
    "    print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "    acc = 100*correct/total\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sojeong/CV/resnet/resnet.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpha/home/sojeong/CV/resnet/resnet.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(params\u001b[39m=\u001b[39mresnet_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpha/home/sojeong/CV/resnet/resnet.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m \u001b[39m## train\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Balpha/home/sojeong/CV/resnet/resnet.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m train(model\u001b[39m=\u001b[39mresnet_model, n_epoch\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, loader\u001b[39m=\u001b[39mtrainloader, optimizer\u001b[39m=\u001b[39moptimizer, criterion\u001b[39m=\u001b[39mcriterion, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpha/home/sojeong/CV/resnet/resnet.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m## test\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpha/home/sojeong/CV/resnet/resnet.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m resnet_acc \u001b[39m=\u001b[39m test(resnet_model, testloader, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "reset_seed(0)\n",
    "resnet_model = ResNet50().to(\"cuda\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=resnet_model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "## train\n",
    "train(model=resnet_model, n_epoch=10, loader=trainloader, optimizer=optimizer, criterion=criterion, device=\"cuda\")\n",
    "## test\n",
    "resnet_acc = test(resnet_model, testloader, device=\"cuda\")\n",
    "\n",
    "print('ResNet Test accuracy: {:.2f}%'.format(resnet_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e73d7685138b7eb2ad9427bd1ae61da544d851fb0421f6c77d829cb8307c0749"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
